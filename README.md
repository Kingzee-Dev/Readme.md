# ShibiMaru: Privacy-First Educational Content Processing System

[![License](https://img.shields.io/badge/License-Proprietary-red.svg)](LICENSE)
[![Python Version](https://img.shields.io/badge/python-3.7%2B-blue)](https://www.python.org/downloads/)
[![Status](https://img.shields.io/badge/Status-Private%20Repository-blueviolet)](https://github.com/)

## üîí Confidential & Proprietary System

**NOTICE**: This repository contains proprietary technology developed by Chhachhi Kingzee in Jalandhar, Punjab, India. All rights reserved. Unauthorized access, use, or distribution is strictly prohibited.

This system is maintained as a private repository for commercial job work applications.

---

## üåü Executive Summary

ShibiMaru is a groundbreaking educational content processing system developed to specifically address the challenges in the Indian education technology sector. What distinguishes ShibiMaru from existing solutions is its **hardware-adaptive architecture** that democratizes advanced NLP capabilities, allowing them to run on infrastructure common in Indian educational settings, from rural schools to top-tier institutions.

The system processes, analyzes, and transforms educational content while maintaining complete data privacy through on-premises processing - a crucial feature for handling sensitive educational materials in compliance with data protection regulations.

## üîç Technology Comparison Matrix

| Capability | ShibiMaru | Google Cloud NLP | Azure AI | Open Source Alternatives | Indian EdTech Platforms |
|------------|-----------|-----------------|----------|--------------------------|-------------------------|
| **Local Processing** | ‚úÖ Complete on-premises | ‚ùå Cloud-only | ‚ùå Cloud-only | ‚ö†Ô∏è Difficult to set up | ‚ùå Usually cloud-dependent |
| **Data Privacy** | ‚úÖ No data leaves premises | ‚ùå Data sent to Google | ‚ùå Data sent to Microsoft | ‚ö†Ô∏è Varies by implementation | ‚ùå Often collects user data |
| **Low-resource Hardware Support** | ‚úÖ Works on 2GB RAM systems | ‚ùå Requires cloud resources | ‚ùå Requires cloud resources | ‚ùå Usually requires significant hardware | ‚ùå Cloud-dependent |
| **Indian Language Support** | ‚úÖ Optimized for Indian languages | ‚ö†Ô∏è Limited effectiveness | ‚ö†Ô∏è Limited effectiveness | ‚ö†Ô∏è Varies widely | ‚ö†Ô∏è Often limited |
| **Offline Operation** | ‚úÖ Full functionality | ‚ùå Requires internet | ‚ùå Requires internet | ‚ö†Ô∏è Limited capabilities | ‚ùå Typically requires internet |
| **Cost Structure** | ‚úÖ One-time deployment cost | ‚ùå Pay-per-use | ‚ùå Pay-per-use | ‚úÖ Free but high setup cost | ‚ùå Subscription model |
| **Education-specific Optimization** | ‚úÖ Built for educational content | ‚ùå Generic NLP | ‚ùå Generic NLP | ‚ùå Generic NLP | ‚ö†Ô∏è Varies by provider |
| **CPU-optimized Training** | ‚úÖ Purpose-built | ‚ùå Requires GPU/TPU | ‚ùå Requires GPU | ‚ùå Typically requires GPU | ‚ùå Uses pre-trained models |

## üí° Innovation Highlights

### 1. Hardware-Adaptive Intelligence
Unlike global tech solutions that assume high-end hardware or cloud infrastructure, ShibiMaru's unique dynamic hardware detection system automatically configures itself to the available resources - from basic laptops in rural classrooms to server clusters in universities.

### 2. Privacy-Centric Architecture
While major cloud providers require sending data to their servers, ShibiMaru processes all information locally, ensuring sensitive educational materials never leave the institution's premises - essential for protecting student data and complying with India's evolving data protection laws.

### 3. CPU-Optimized Training
Developed specifically for environments where GPUs are unavailable, ShibiMaru's innovative CPU training path allows educational institutions to train and customize models on standard computers - a capability absent from all major NLP platforms.

### 4. Hybrid CPU-GPU Processing
For institutions with limited GPU access, ShibiMaru's unique hybrid mode intelligently distributes workloads between CPU and GPU, maximizing performance while maintaining reliability - a feature not found in mainstream AI frameworks.

### 5. Indian Language Specialization
Unlike global NLP platforms with limited support for Indian languages, ShibiMaru is built from the ground up with India's linguistic diversity in mind, providing deeper understanding of educational content in multiple Indian languages.

## üîÑ System Architecture

ShibiMaru is built with a modular architecture designed for exceptional flexibility:

### Core Components:

1. **Document Processing Engine**
   - Extracts content from various document formats (PDF, DOC, etc.)
   - Preserves document structure and metadata
   - Memory-efficient processing for large documents

2. **Hardware Adaptation Layer**
   - Dynamic detection of available computing resources
   - Automatic optimization of processing parameters
   - Seamless scaling from low-end to high-end hardware

3. **Training Orchestration System**
   - Intelligent model selection based on hardware constraints
   - CPU-optimized training for resource-limited environments
   - Hybrid CPU-GPU processing for maximum efficiency

4. **Privacy-Preserving Analysis**
   - All processing occurs locally without data transmission
   - Flexible deployment options within institutional firewalls
   - No dependency on external APIs or services

5. **Education-Specific Classification**
   - Subject matter identification
   - Educational level assessment
   - Curriculum alignment detection

## üìã Key Technical Features

- **Hardware-aware optimization**: Automatically selects models and parameters based on available resources
- **Thread optimization**: Intelligently distributes workloads across available CPU cores
- **Memory-efficient processing**: Operates within tight memory constraints
- **Gradient accumulation**: Enables training on smaller batch sizes without performance loss
- **Dynamic document chunking**: Processes large documents on limited memory
- **Automatic model selection**: Chooses appropriate model size based on hardware capabilities
- **Early stopping**: Optimizes training time while maintaining quality
- **Configurable precision**: Adapts numerical precision based on available hardware
- **Comprehensive test suite**: Ensures reliability across diverse environments

## üîß Deployment Requirements

### Minimum Configuration
- Python 3.7+
- 2GB RAM
- Dual-core CPU
- 5GB storage space

### Recommended Configuration
- Python 3.8+
- 8GB+ RAM
- Quad-core CPU
- CUDA-compatible GPU (optional)
- 20GB+ storage space

## üíª Installation (Authorized Users Only)

```bash
# Clone the repository (requires authorization)
git clone https://github.com/kingzeedev/Kamikaze.git
cd Kamikaze

# Create a virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

## üöÄ Usage Examples

```bash
# Process documents with automatic hardware optimization
python ShibiMaru/scripts/pipeline.py process --data_dir /path/to/data

# Train models on a resource-constrained system
python ShibiMaru/scripts/pipeline.py train-all-models --use_cpu_trainer --model small

# Run the full pipeline from processing to deployment
python ShibiMaru/scripts/pipeline.py fullstack --data_dir /path/to/data

# Run model optimization
python ShibiMaru/scripts/pipeline.py optimize --model_dir /path/to/models
```

## üìä Market Differentiation

### Global Tech Platforms (Google, Microsoft, AWS)
These platforms provide powerful NLP capabilities but **require internet connectivity** and **send data to their servers** - making them unsuitable for sensitive educational contexts where data privacy is paramount. Their solutions also typically **require significant computational resources** and come with **ongoing subscription costs**.

### Open Source Alternatives
While open source NLP libraries exist, they **lack educational content specialization** and typically **require significant technical expertise** to deploy and maintain. They also generally **demand substantial computational resources** and offer **limited support for Indian languages**.

### Indian EdTech Market
Most existing Indian EdTech platforms focus on content delivery rather than processing or intelligence. When they do offer content understanding, it's typically through **cloud-based services** that **compromise data privacy**. None offer ShibiMaru's comprehensive hardware adaptation that enables deployment across diverse infrastructure environments.

## üìö Commercial Applications

ShibiMaru's technology is available for commercial licensing and custom implementation. Our system is particularly valuable for:

1. **Educational publishers** needing to process and classify educational content
2. **EdTech companies** requiring content understanding without privacy concerns
3. **Educational institutions** looking to digitize and analyze their materials
4. **Government education departments** processing curriculum documents
5. **Assessment companies** analyzing and categorizing question banks

## üë• About the Developer

Developed by **Chhachhi Kingzee** in Jalandhar, Punjab, India, ShibiMaru represents a significant advancement in making AI technology accessible and relevant to Indian educational contexts. The system reflects a deep understanding of both technical constraints and pedagogical needs specific to the Indian educational landscape.

## üìú Legal Notice

This codebase and documentation represent proprietary technology. All rights reserved. The system is maintained as a private repository for commercial applications, including customized implementations and licensed deployments.

Unauthorized access, reproduction, or distribution is strictly prohibited and may result in legal action.

For licensing inquiries, please contact the developer directly.

---

## ‚öôÔ∏è Technical Implementation Details

ShibiMaru's core innovation lies in its ability to automatically detect and adapt to hardware constraints while maintaining high-quality processing and analysis. This is achieved through:

### Hardware-Aware Operation

```python
# Example of hardware detection and optimization
def detect_hardware_capabilities():
    """Comprehensive hardware detection for optimal resource allocation"""
    import platform
    import psutil
    
    hardware_info = {
        "system": platform.system(),
        "processor": platform.processor(),
        "memory": {
            "total_gb": round(psutil.virtual_memory().total / (1024**3), 2),
            "available_gb": round(psutil.virtual_memory().available / (1024**3), 2),
        },
        "cpu": {
            "physical_cores": psutil.cpu_count(logical=False),
            "logical_cores": psutil.cpu_count(logical=True),
        }
    }
    
    # GPU detection when available
    try:
        import torch
        hardware_info["gpu"] = {
            "available": torch.cuda.is_available(),
            "count": torch.cuda.device_count() if torch.cuda.is_available() else 0,
            "names": [torch.cuda.get_device_name(i) for i in range(torch.cuda.device_count())] 
                     if torch.cuda.is_available() else []
        }
    except ImportError:
        hardware_info["gpu"] = {"available": False, "count": 0, "names": []}
    
    return hardware_info
```

### Dynamic Model Selection

```python
def select_optimal_model(dataset_size, system_memory_gb, requested_model=None):
    """
    Select the best model based on dataset size and available memory.
    """
    # Memory-based model selection
    if system_memory_gb < 2.0:
        model_name = CPU_FRIENDLY_MODELS["tiny"]  # 17M parameters
    elif system_memory_gb < 4.0:
        model_name = CPU_FRIENDLY_MODELS["mini"]  # 33M parameters
    elif system_memory_gb < 8.0:
        model_name = CPU_FRIENDLY_MODELS["small"]  # 67M parameters
    else:
        model_name = CPU_FRIENDLY_MODELS["base_multi"]  # 134M parameters
    
    # Set sequence length based on memory
    max_seq_length = 128 if system_memory_gb < 2.0 else 256 if system_memory_gb < 4.0 else 512
    
    # Determine batch size based on memory
    batch_size = 1 if system_memory_gb < 2.0 else 2 if system_memory_gb < 4.0 else 4 
                if system_memory_gb < 8.0 else 8
    
    return model_name, max_seq_length, batch_size
```

These proprietary algorithms enable ShibiMaru to democratize access to advanced NLP capabilities in educational settings with varying technical resources - a unique capability not found in existing commercial or open-source solutions.
